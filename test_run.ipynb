{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8e54e2a",
   "metadata": {},
   "source": [
    "## Energy PLUS PLUS - ML Demo/ Graph Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa54e4b5",
   "metadata": {},
   "source": [
    "This notebook has code for running the Energy++ ML model using yolov5 and then structuring the obtained bounding boxes into a connectivity graph.\n",
    "\n",
    "In order to use this notebook, please ensure that this file is inside the yolov5 repository folder which you can clone from [here](https://github.com/ultralytics/yolov5). Also, the image that needs to be segmented needs to have the name \"test.png\" at the moment which ofcourse can be changed but you would have to edit the code.\n",
    "\n",
    "Also, make sure the weights/model you wish to load is placed in yolov5/runs/train/exp/(name of your weights file .pt or .pth usually)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2d1cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from IPython.display import display\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa08ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"test.png\"\n",
    "path = cv2.imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb3443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model with the best run so far\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train/exp9/weights/best.pt',)\n",
    "model.conf = 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44336dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model on a test image\n",
    "model.eval()\n",
    "result = model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a42cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f28e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the co-ordinates of the bounding boxes\n",
    "display(PIL.Image.open(\"test.png\"))\n",
    "bb_dataframe = result.pandas().xyxy[0]\n",
    "print(bb_dataframe)\n",
    "# for idx, row in bb_dataframe.iterrows():\n",
    "#     rect = patches.Bbox([row['xmin'],row['ymin']],[row['xmax'],row['ymax']])\n",
    "#     print(row['xmin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extracting the classes with detected frequency\n",
    "# import numpy as np\n",
    "# co_ordinates = result.pred[0]\n",
    "# print(co_ordinates.shape)\n",
    "# new_points = []\n",
    "\n",
    "# for rows in co_ordinates:\n",
    "#     x_c = float((rows[0] + rows[2])/2)\n",
    "#     y_c = float((rows[1] + rows[3])/2)\n",
    "#     centroids = torch.tensor([x_c,y_c], device = \"cuda\")\n",
    "#     rows = torch.cat((rows, centroids), 0)\n",
    "#     new_points.append(rows)\n",
    "# new_points = torch.stack(new_points)\n",
    "# result.pred[0] = new_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550055e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of overlap above which the rooms are considered neighbors\n",
    "IOU = 0.2\n",
    "# orthogonal overlap\n",
    "offset = 200.0\n",
    "# multiplication factor between pixels and image - empirically calculated for now\n",
    "x_factor = 1.68*100\n",
    "y_factor = 1.685*100\n",
    "# factor of change in area\n",
    "area_factor = x_factor* y_factor\n",
    "# height assumed constant for the moment\n",
    "height = 3.0 \n",
    "# wll thickness - considered constant for the moment\n",
    "thickness = 0.25\n",
    "#volume to be calculated\n",
    "volume = 0.0\n",
    "\n",
    "# Numpy arraa of results from model\n",
    "result_val = result.pred\n",
    "# Name of elements in the image - room/windows/doors etc\n",
    "entity_labels = []\n",
    "\n",
    "# indices for elements\n",
    "room_count = 0\n",
    "window_count = 0\n",
    "door_count = 0\n",
    "\n",
    "# Graph for connectivity of room\n",
    "connectivity = dict()\n",
    "\n",
    "# Add element names to the labels \n",
    "for row in result_val[0]:\n",
    "    if int(row[-1]) == 0:\n",
    "        entity_labels.append(\"room\"+str(room_count))\n",
    "        room_count += 1\n",
    "    elif int(row[-1]) == 1:\n",
    "        entity_labels.append(\"window\"+str(window_count))\n",
    "        window_count += 1\n",
    "    else:\n",
    "        entity_labels.append(\"door\"+str(door_count))\n",
    "        door_count += 1\n",
    "        \n",
    "# reversing the list to make it consistent with detect.py results from the yolov5\n",
    "entity_labels = list(reversed(entity_labels))\n",
    "\n",
    "# setting attributes for each room \n",
    "for i in range(len(entity_labels)):\n",
    "    connectivity[entity_labels[i]] = {\"neighbors\":[],\"wall\":[],\"area\":0.0, \"thickness\": 0.25, \"volume\":0.0}\n",
    "\n",
    "# access the numpy array of results - result_val is a list with length 1 - the 0th element is the prediction\n",
    "temp = result_val[0]\n",
    "# array to store the centers of all bounding boxes - used later for labels\n",
    "centers = []\n",
    "\n",
    "# Finding connectivity and storing every connection with attributes of each room\n",
    "for i in range(len(temp)):\n",
    "    \n",
    "    # coordinates of the bounding box of the single image to be matched against all others\n",
    "    x1min, y1min, x1max, y1max = temp[i][0].item(), temp[i][1].item(), temp[i][2].item(), temp[i][3].item() \n",
    "    # centre of the bounding box\n",
    "    x1c, y1c = (x1min+x1max)/2 , (y1min + y1max)/2\n",
    "    # collecting centers of each bounding box\n",
    "    if (x1c,y1c) not in centers:\n",
    "        centers.append((x1c, y1c))\n",
    "    # area and volume of the room to be matched\n",
    "    area = ((x1max-x1min) * (y1max-y1min))/area_factor \n",
    "    volume = area * height\n",
    "    connectivity[entity_labels[i]][\"area\"] = area\n",
    "    connectivity[entity_labels[i]][\"volume\"] = volume\n",
    "    # Comparing i th element with all others\n",
    "    for j in range (len(temp)):\n",
    "        if i!=j:\n",
    "            x2min, y2min, x2max, y2max = temp[j][0].item(), temp[j][1].item(), temp[j][2].item(), temp[j][3].item()\n",
    "            # x2c, y2c = (x2min+x2max)/2 , (y2min + y2max)/2  \n",
    "            # check for neighbors and add only if it has not been added yet           \n",
    "            if entity_labels[j] not in connectivity[entity_labels[i]][\"neighbors\"]:\n",
    "                # check if the box i and j overlap on the \"right\" by offset amounts\n",
    "                if abs(x1max - x2min)<=offset:\n",
    "                    # standard iou technique - calculate overlap\n",
    "                    overlap = abs(min(y1max,y2max) - max(y1min, y2min))\n",
    "                    union = y1max - y1min + y2max - y2min - overlap\n",
    "                    # the percentage of overlap is above IOU, consider it a true neighbor\n",
    "                    intersection = overlap/union\n",
    "                    #print(\"right\", intersection)\n",
    "                    if intersection>IOU:\n",
    "                            connectivity[entity_labels[i]][\"neighbors\"].append(entity_labels[j])\n",
    "                            connectivity[entity_labels[i]][\"wall\"].append(overlap/y_factor)\n",
    "                # check for left neighbors\n",
    "                if abs(x1min - x2max)<=offset:\n",
    "                    overlap = abs(min(y1max,y2max) - max(y1min, y2min))\n",
    "                    union = y1max - y1min + y2max - y2min - overlap\n",
    "                    intersection = overlap/union\n",
    "                    #print(\"left\", intersection)\n",
    "                    if intersection>IOU:\n",
    "                            connectivity[entity_labels[i]][\"neighbors\"].append(entity_labels[j])\n",
    "                            connectivity[entity_labels[i]][\"wall\"].append(overlap//y_factor)\n",
    "                # check for top neighbors          \n",
    "                if abs(y1max - y2min)<=offset:\n",
    "                    overlap = abs(min(x1max,x2max) - max(x1min, x2min))\n",
    "                    union = x1max - x1min + x2max - x2min - overlap\n",
    "                    intersection = overlap/union \n",
    "                    #print(\"top\", intersection)\n",
    "                    if intersection>IOU:\n",
    "                            connectivity[entity_labels[i]][\"neighbors\"].append(entity_labels[j])\n",
    "                            connectivity[entity_labels[i]][\"wall\"].append(overlap/x_factor)\n",
    "                # check for bottom neighbors\n",
    "                if abs(y1min - y2max)<=offset:\n",
    "                    overlap = abs(min(x1max,x2max) - max(x1min, x2min))\n",
    "                    union = x1max - x1min + x2max - x2min - overlap\n",
    "                    intersection = overlap/union\n",
    "                    #print(\"bottom\", intersection)\n",
    "                    if intersection>IOU:   \n",
    "                            connectivity[entity_labels[i]][\"neighbors\"].append(entity_labels[j])\n",
    "                            connectivity[entity_labels[i]][\"wall\"].append(overlap/x_factor)\n",
    "# Print connectivity and do a sanity check with the image\n",
    "print(connectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf438b91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rendering the image with bounding boxes\n",
    "result.render(labels=True)\n",
    "result.save(labels=True, save_dir=\"\")\n",
    "image = PIL.Image.open(\".2/image0.jpg\")\n",
    "draw  = PIL.ImageDraw.Draw(image)\n",
    "font  = PIL.ImageFont.truetype(\"arial.ttf\", 50, encoding=\"unic\")\n",
    "for text, coordinates in zip(entity_labels, centers):\n",
    "    # annotate each room and save with each annotation\n",
    "    draw.text( (coordinates[0],coordinates[1]), text, font=font, fill=\"#0000FF\")\n",
    "    image.save(\".2/image0.png\",\"png\")\n",
    "draw.text([1,5000],str(connectivity), font=font, fill=\"#0000FF\")\n",
    "image.save(\"image0.png\",\"png\")\n",
    "display(PIL.Image.open(\"image0.png\"))\n",
    "print(connectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf .2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eb0f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
